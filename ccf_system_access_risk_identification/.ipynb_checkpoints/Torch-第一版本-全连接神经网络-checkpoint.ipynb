{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3947fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:38:50.089576Z",
     "start_time": "2022-11-06T10:38:47.124811Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle as pkl\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import scorpyo as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e946764a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:38:50.094752Z",
     "start_time": "2022-11-06T10:38:50.091156Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保证每次结果一样\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076d56fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:38:50.102600Z",
     "start_time": "2022-11-06T10:38:50.095973Z"
    }
   },
   "outputs": [],
   "source": [
    "path_project = r'/Users/liliangshan/workspace/python/01_datasets/ccf_system_access_risk_identification'\n",
    "\n",
    "# path dir\n",
    "path_row_data = os.path.join(path_project, 'row_data')\n",
    "path_new_data = os.path.join(path_project, 'new_data')\n",
    "path_results  = os.path.join(path_project, 'results')\n",
    "path_results_version  = os.path.join(path_results, 'version_2')\n",
    "\n",
    "# path row_data\n",
    "path_train = os.path.join(path_row_data, 'train.csv')\n",
    "path_test  = os.path.join(path_row_data, 'evaluation_public.csv')\n",
    "path_sample_submission = os.path.join(path_row_data, 'submit_example.csv')\n",
    "\n",
    "## results\n",
    "path_output_report = os.path.join(path_results, '01_原始数据探察_20221014.xlsx')\n",
    "\n",
    "## 模型保存\n",
    "path_results_model = os.path.join(path_results, 'models')\n",
    "\n",
    "y_label = \"is_risk\"\n",
    "\n",
    "\n",
    "# new_train_data\n",
    "path_new_train_cate = os.path.join(path_new_data, 'train_cate.pkl')\n",
    "path_new_test_cate  = os.path.join(path_new_data, 'test_cate.pkl')\n",
    "\n",
    "path_new_train_time_sequence = os.path.join(path_new_data, 'train_time_sequence.pkl')\n",
    "path_new_test_time_sequence  = os.path.join(path_new_data, 'test_time_sequence.pkl')\n",
    "\n",
    "path_new_train_time_sequence_woe = os.path.join(path_new_data, 'train_time_sequence_woe.pkl')\n",
    "path_new_test_time_sequence_woe  = os.path.join(path_new_data, 'test_time_sequence_woe.pkl')\n",
    "\n",
    "path_new_train_cumsum = os.path.join(path_new_data, 'train_cumsum.pkl')\n",
    "path_new_test_cumsum = os.path.join(path_new_data, 'test_cumsum.pkl')\n",
    "\n",
    "path_new_train_cumsum_woe = os.path.join(path_new_data, 'train_cumsum_woe.pkl')\n",
    "path_new_test_cumsum_woe = os.path.join(path_new_data, 'test_cumsum_woe.pkl')\n",
    "\n",
    "path_new_train_embeding = os.path.join(path_new_data, 'train_embeding.pkl')\n",
    "path_new_test_embeding = os.path.join(path_new_data, 'test_embeding.pkl')\n",
    "\n",
    "path_new_train_time_sequence_sp_woe = os.path.join(path_new_data, 'train_time_sequence_sp_woe.pkl')\n",
    "path_new_test_time_sequence_sp_woe  = os.path.join(path_new_data, 'test_time_sequence_sp_woe.pkl')\n",
    "\n",
    "path_new_train_cumsum_sp_woe = os.path.join(path_new_data, 'train_cumsum_sp_woe.pkl')\n",
    "path_new_test_cumsum_sp_woe = os.path.join(path_new_data, 'test_cumsum_sp_woe.pkl')\n",
    "\n",
    "\n",
    "path_new_train_sp_cate = os.path.join(path_new_data, 'train_sp_cate.pkl')\n",
    "path_new_test_sp_cate  = os.path.join(path_new_data, 'test_sp_cate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59023d0d",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5092acf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:38:50.108342Z",
     "start_time": "2022-11-06T10:38:50.104947Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_pkl(data, path_data):\n",
    "    \"\"\"将数据保存为pkl\"\"\"\n",
    "    with open(path_data, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "        \n",
    "def read_pkl(path_data):\n",
    "    \"\"\"读取pkl格式数据\"\"\"\n",
    "    with open(path_data, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"\n",
    "    获取已使用时间\n",
    "    :param start_time: 程序开始运行时间\n",
    "    :return: 经历时间\n",
    "    \"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcb1a5",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c07ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:38:51.161237Z",
     "start_time": "2022-11-06T10:38:50.109656Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_cate = read_pkl(path_new_train_sp_cate)\n",
    "df_val_cate = read_pkl(path_new_test_sp_cate)\n",
    "\n",
    "df_train_time_sequence = read_pkl(path_new_train_time_sequence)\n",
    "df_val_time_sequence = read_pkl(path_new_test_time_sequence)\n",
    "\n",
    "df_train_cumsum = read_pkl(path_new_train_cumsum)\n",
    "df_val_cumsum = read_pkl(path_new_test_cumsum)\n",
    "\n",
    "df_train_embeding = read_pkl(path_new_train_embeding)\n",
    "df_val_embeding = read_pkl(path_new_test_embeding)\n",
    "\n",
    "df_raw_train = pd.read_csv(path_train)\n",
    "df_raw_val  = pd.read_csv(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e155a067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:39:37.166372Z",
     "start_time": "2022-11-06T10:38:51.162474Z"
    }
   },
   "outputs": [],
   "source": [
    "df_row_train = pd.merge(left=df_train_cate, right=df_train_embeding, on='id')\n",
    "df_row_val = pd.merge(left=df_val_cate, right=df_val_embeding, on='id')\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_raw_train[['id', y_label]], on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_raw_val[['id']], on='id')\n",
    "\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_train_cumsum, on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_val_cumsum, on='id')\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_train_time_sequence, on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_val_time_sequence, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59e92d",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9543f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:39:37.172152Z",
     "start_time": "2022-11-06T10:39:37.167514Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifyDataset(Dataset):\n",
    "    def __init__(self, data, label_name, exclude=[], is_test=False):\n",
    "        self.dataset = pd.read_csv(data) if isinstance(data, str) else data\n",
    "        self.feats = self.dataset.drop(columns=exclude+[label_name]).fillna(-1)\n",
    "        \n",
    "        self.is_test = is_test\n",
    "        if not self.is_test:\n",
    "            self.labels = self.dataset[label_name]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        res_feats = torch.tensor([item for item in self.feats.iloc[idx, :]]).float()\n",
    "        if not self.is_test:\n",
    "            res_labels = torch.tensor(self.labels[idx]).long()\n",
    "        else:\n",
    "            res_labels = None\n",
    "        \n",
    "        return res_feats, res_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f84bd",
   "metadata": {},
   "source": [
    "## NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517e6791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:39:37.178759Z",
     "start_time": "2022-11-06T10:39:37.173329Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(ClassifyModel, self).__init__()\n",
    "        \n",
    "        self.fc1   = nn.Linear(in_features=input_dim, out_features=256, bias=False)\n",
    "        self.ac1   = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.fc2   = nn.Linear(in_features=256, out_features=128)\n",
    "        self.ac2   = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.fc3   = nn.Linear(in_features=128, out_features=64)\n",
    "        self.ac3   = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.fc4   = nn.Linear(in_features=64, out_features=32)\n",
    "        self.ac4   = nn.ReLU()\n",
    "        self.drop4 = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.fc5   = nn.Linear(in_features=32, out_features=out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45e9354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:39:37.184131Z",
     "start_time": "2022-11-06T10:39:37.180284Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(ClassifyModel, self).__init__()\n",
    "        \n",
    "        self.fc1   = nn.Linear(in_features=input_dim, out_features=32, bias=False)\n",
    "        self.ac1   = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.fc5   = nn.Linear(in_features=32, out_features=out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d84126",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e03e3f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:23.268943Z",
     "start_time": "2022-11-06T10:39:37.187496Z"
    }
   },
   "outputs": [],
   "source": [
    "df_row_train = pd.merge(left=df_train_cate, right=df_train_embeding, on='id')\n",
    "df_row_val = pd.merge(left=df_val_cate, right=df_val_embeding, on='id')\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_raw_train[['id', y_label]], on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_raw_val[['id']], on='id')\n",
    "\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_train_cumsum, on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_val_cumsum, on='id')\n",
    "\n",
    "df_row_train = pd.merge(left=df_row_train, right=df_train_time_sequence, on='id')\n",
    "df_row_val = pd.merge(left=df_row_val, right=df_val_time_sequence, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b70b3985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:24.916272Z",
     "start_time": "2022-11-06T10:40:23.270223Z"
    }
   },
   "outputs": [],
   "source": [
    "df_raw_train = pd.read_csv(path_train)\n",
    "train_ids = set(df_raw_train[df_raw_train['op_month']!='2022-04']['id'].unique())\n",
    "\n",
    "df_train = df_row_train[df_row_train['id'].isin(train_ids)].reset_index(drop=True)\n",
    "df_test  = df_row_train[~df_row_train['id'].isin(train_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5a1597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:24.980282Z",
     "start_time": "2022-11-06T10:40:24.924389Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train = df_train[feats+['id', y_label]]\n",
    "df_test  = df_test[feats+['id', y_label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c37ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:25.005729Z",
     "start_time": "2022-11-06T10:40:24.981538Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ClassifyDataset(df_train, y_label, exclude=['id'])\n",
    "test_dataset  = ClassifyDataset(df_test, y_label, exclude=['id'])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=64,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=64,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77d42d",
   "metadata": {},
   "source": [
    "## Trainning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27978dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:25.010878Z",
     "start_time": "2022-11-06T10:40:25.006970Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim=df_train.shape[1]-2\n",
    "out_dim=2\n",
    "\n",
    "# 实例化模型\n",
    "model = ClassifyModel(input_dim=input_dim, out_dim=out_dim)\n",
    "# 损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df485b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:40:25.018699Z",
     "start_time": "2022-11-06T10:40:25.012335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifyModel(\n",
       "  (fc1): Linear(in_features=100, out_features=32, bias=False)\n",
       "  (ac1): ReLU()\n",
       "  (drop1): Dropout(p=0.02, inplace=False)\n",
       "  (fc5): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fabdcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:41:08.815726Z",
     "start_time": "2022-11-06T10:40:25.020236Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]\n",
      "Iter:     20,  Train Loss: 0.9198,  Train AUC: 50.0000%,  Val Loss: 169.9,  Val AUC: 50.2024%,  Time: 0:00:02 \n",
      "Iter:     40,  Train Loss: 0.9708,  Train AUC: 50.0000%,  Val Loss: 112.6,  Val AUC: 50.2078%,  Time: 0:00:04 \n",
      "Iter:    220,  Train Loss: 1.336,  Train AUC: 50.0000%,  Val Loss: 6.713e+05,  Val AUC: 50.5846%,  Time: 0:00:19 \n",
      "No optimization for a long time, auto-stopping...\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "total_batch = 1     # 记录进行到多少batch\n",
    "dev_best_metric = 0\n",
    "last_improve = 0    # 记录上次验证集loss下降的batch数\n",
    "flag = False        # 记录上次验证集loss下降的batch数\n",
    "epoch_num = 1000      # 训练的epoch数\n",
    "iter_num = 20       # 迭代输出的次数\n",
    "early_stopping_iter_num = 500 # 早停的轮数\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    print('Epoch [{}/{}]'.format(epoch +1, epoch_num))\n",
    "    for i, (train_feats, train_labels) in enumerate(train_loader):\n",
    "        # 前馈\n",
    "        y_pred = model(train_feats)\n",
    "        # 损失\n",
    "        loss = criterion(y_pred, train_labels)\n",
    "        loss_list.append(loss.item())\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        if total_batch%iter_num==0:\n",
    "            # 每多少轮输出在训练集和验证集上的效果\n",
    "            y_true = train_labels.data.cpu()\n",
    "            y_pred = F.softmax(y_pred, dim=1).data.cpu()[:,1]\n",
    "            train_metric = roc_auc_score(y_true, y_pred)\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "            dev_loss = 0\n",
    "            dev_pred = np.array([])\n",
    "            dev_label = np.array([])\n",
    "            with torch.no_grad():\n",
    "                for test_feats, test_labels in test_loader:\n",
    "                    dev_y_pred = model(test_feats)\n",
    "                    loss = F.cross_entropy(dev_y_pred, test_labels)\n",
    "                    dev_loss += loss\n",
    "                    \n",
    "                    dev_label = np.append(dev_label, test_labels.data.cpu())\n",
    "                    dev_pred = np.append(dev_pred, F.softmax(dev_y_pred, dim=1).data.cpu()[:,1])\n",
    "  \n",
    "            dev_metric = roc_auc_score(dev_label, dev_pred )\n",
    "                \n",
    "            if dev_best_metric < dev_metric:\n",
    "                dev_best_metric = dev_metric\n",
    "                if total_batch > 100500:\n",
    "                    path_model_save = os.path.join(path_results_model, time.strftime('mlp_%Y%m%d%H%M_')+'%.5f.csv'%dev_metric)\n",
    "                    torch.save(model.state_dict(), path_model_save)\n",
    "                    improve = \"*\"\n",
    "                    last_improve = total_batch    \n",
    "                else:\n",
    "                    improve = ''\n",
    "                    \n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = 'Iter: {0:>6},  Train Loss: {1:>5.4},  Train AUC: {2:>6.4%},  Val Loss: {3:>5.4},  Val AUC: {4:>6.4%},  Time: {5} {6}'\n",
    "                print(msg.format(total_batch, loss.item(), train_metric, dev_loss, dev_metric, time_dif, improve))\n",
    "                model.train()\n",
    "            total_batch += 1\n",
    "            if total_batch - last_improve > early_stopping_iter_num:\n",
    "                # 验证集loss超过1000batch没下降，结束训练\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break\n",
    "        total_batch+=1\n",
    "    if flag:\n",
    "        break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ddb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f2f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:scorpyo]",
   "language": "python",
   "name": "conda-env-scorpyo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
