{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4b06aa",
   "metadata": {},
   "source": [
    "<div \n",
    "     style=\"padding: 20px; \n",
    "            color: yellow;\n",
    "            margin: 0;\n",
    "            font-size: 250%;\n",
    "            text-align: center;\n",
    "            display: fill;\n",
    "            border-radius: 5px;\n",
    "            background-color: #0daae3;\n",
    "            overflow: hidden;\n",
    "            font-weight: 700;\n",
    "            border: 5px solid black;\"\n",
    "     >\n",
    "            Candidate ReRank Model using Handcrafted Rules\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fefe20",
   "metadata": {},
   "source": [
    "## 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a21cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:51:29.427219Z",
     "start_time": "2022-11-11T14:51:28.205604Z"
    },
    "execution": {
     "iopub.execute_input": "2022-11-13T06:36:32.667233Z",
     "iopub.status.busy": "2022-11-13T06:36:32.666797Z",
     "iopub.status.idle": "2022-11-13T06:36:32.677041Z",
     "shell.execute_reply": "2022-11-13T06:36:32.675964Z",
     "shell.execute_reply.started": "2022-11-13T06:36:32.667192Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_365/3787790681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle \n",
    "import glob\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import cudf\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = r'/workspace/datasets/otto'\n",
    "\n",
    "# path dir\n",
    "path_row_data = os.path.join(path_project, 'row_data')\n",
    "path_new_data = os.path.join(path_project, 'new_data')\n",
    "path_results  = os.path.join(path_project, 'results')\n",
    "\n",
    "# path row_data\n",
    "path_train = os.path.join(path_row_data, 'train.jsonl')\n",
    "path_test  = os.path.join(path_row_data, 'test.jsonl')\n",
    "path_sample_submission = os.path.join(path_row_data, 'sample_submission.csv')\n",
    "\n",
    "# parquet 格式的文件存放路径\n",
    "path_parquet = os.path.join(path_new_data, 'parquet')\n",
    "path_parquet_train = os.path.join(path_parquet, 'train')\n",
    "path_parquet_test = os.path.join(path_parquet, 'test')\n",
    "\n",
    "path_top_40_carts_orders = os.path.join(path_new_data, 'top_40_carts_orders')\n",
    "path_top_40_buy2buy = os.path.join(path_new_data, 'top_40_buy2buy')\n",
    "path_top_40_clicks = os.path.join(path_new_data, 'top_40_clicks')\n",
    "\n",
    "VERSION = 1\n",
    "\n",
    "path_submission = os.path.join(path_results, 'version_{}'.format(VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b62cf1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:51:32.525043Z",
     "start_time": "2022-11-11T14:51:32.515439Z"
    },
    "execution": {
     "iopub.execute_input": "2022-11-13T06:36:36.320119Z",
     "iopub.status.busy": "2022-11-13T06:36:36.319418Z",
     "iopub.status.idle": "2022-11-13T06:36:36.330939Z",
     "shell.execute_reply": "2022-11-13T06:36:36.329880Z",
     "shell.execute_reply.started": "2022-11-13T06:36:36.320082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129个数据集将分为22个部分进行处理\n"
     ]
    }
   ],
   "source": [
    "files = sorted(glob.glob('{}/*'.format(path_parquet_train)))\n",
    "chunk = int(np.ceil(len(files)/6))\n",
    "\n",
    "print(\"{}个数据集将分为{}个部分进行处理\".format(len(files), chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5dcd7",
   "metadata": {},
   "source": [
    "## Step 1 Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740de5c",
   "metadata": {},
   "source": [
    "### “点击/收藏/购买”共现矩阵-类别加权\n",
    "假设用户当前浏览的商品会影响用户后续浏览商品的选择，因此构造商品-商品共现矩阵，其中用户对不同商品的动作代表的商品间的不同权重，因此可以通过这种逻辑来基于用户当前浏览的商品来预测下一个客户可能会浏览的商品\n",
    "+ 这里用于当前商品的下一个浏览商品的推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b0cc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T05:57:40.190068Z",
     "iopub.status.busy": "2022-11-13T05:57:40.189813Z",
     "iopub.status.idle": "2022-11-13T06:06:08.519550Z",
     "shell.execute_reply": "2022-11-13T06:06:08.518518Z",
     "shell.execute_reply.started": "2022-11-13T05:57:40.190043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "CPU times: user 6min 5s, sys: 2min 20s, total: 8min 25s\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "type_labels = {\"clicks\":0, \"carts\":1, \"orders\":2} # 类别映射字典\n",
    "type_weight = {0:1, 1:6, 2:3} # 权重映射字典\n",
    "\n",
    "disk_pices = 4\n",
    "size = 1.86e6/disk_pices\n",
    "\n",
    "# 分块计算共现矩阵\n",
    "for part in range(disk_pices):\n",
    "    \n",
    "    # 分块读取数据集\n",
    "    for j in range(6):\n",
    "        a = j*chunk\n",
    "        b = min((j+1)*chunk, len(files))\n",
    "        print(\"正在处理第{}-{}部分的数据\".format(a, b))\n",
    "\n",
    "        for k in range(a, b):\n",
    "            # 读取数据\n",
    "            df = cudf.read_parquet(files[k])\n",
    "            df.ts = (df.ts/1000).astype('int32')\n",
    "            df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "            df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "            # 对数量短的session进行过滤\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n', axis=1)\n",
    "            # 创建商品对\n",
    "            df = df.merge(df, on='session')\n",
    "            df = df.loc[((df.ts_x-df.ts_y).abs()<24*60*60)&(df.aid_x!=df.aid_y)]\n",
    "            # 分步统计，节省内存\n",
    "            df = df.loc[(df.aid_x >= part*size)&(df.aid_x < (part+1)*size)]\n",
    "            # 分配权重\n",
    "            df = df[['session', 'aid_x', 'aid_y', 'type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = df.type_y.map(type_weight)\n",
    "            df = df[['aid_x', 'aid_y', 'wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x', 'aid_y']).wgt.sum()\n",
    "            # 合并分块\n",
    "            if k == a:\n",
    "                tmp2 = df\n",
    "            else:\n",
    "                #tmp2 = pd.concat([tmp2, df]).filna(0)\n",
    "                tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k, ' ', end='')\n",
    "        print()\n",
    "        if a==0: tmp = tmp2\n",
    "        else:  tmp = tmp.add(tmp2, fill_value=0)  # tmp = pd.concat([tmp, tmp]).filna(0)            # tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # 将矩阵转换为dict\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x', 'wgt'], ascending=[True, False])\n",
    "    # 保存前40\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n', axis=1)\n",
    "    # 分块保存在磁盘中\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    os.makedirs(path_top_40_carts_orders, exist_ok=True)\n",
    "    with open(os.path.join(path_top_40_carts_orders, 'top_40_carts_orders_v{}_{}.pkl'.format(VERSION, part)), 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd35e62",
   "metadata": {},
   "source": [
    "### “收藏/购买”共现矩阵\n",
    "假设用户当前收藏或购买过的商品会影响用户后续的收藏/购买，因此构造商品-商品共现矩阵，其中这里假定收藏/购买的权重一致，因此可以通过这种逻辑来基于用户当前收藏/购买的商品来预测用户下一个可能会收藏/购买的商品。\n",
    "+ 这里用户预测用户下一个可能收藏/购买的商品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee525b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T06:06:08.522718Z",
     "iopub.status.busy": "2022-11-13T06:06:08.522334Z",
     "iopub.status.idle": "2022-11-13T06:09:39.224166Z",
     "shell.execute_reply": "2022-11-13T06:09:39.223147Z",
     "shell.execute_reply.started": "2022-11-13T06:06:08.522681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "CPU times: user 2min 54s, sys: 35.2 s, total: 3min 29s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "type_labels = {\"clicks\":0, \"carts\":1, \"orders\":2} \n",
    "\n",
    "disk_pices = 4\n",
    "size = 1.86e6/disk_pices\n",
    "\n",
    "# 分块计算共现矩阵\n",
    "for part in range(disk_pices):\n",
    "    \n",
    "    # 分块读取数据集\n",
    "    for j in range(6):\n",
    "        a = j*chunk\n",
    "        b = min((j+1)*chunk, len(files))\n",
    "        print(\"正在处理第{}-{}部分的数据\".format(a, b))\n",
    "\n",
    "        for k in range(a, b):\n",
    "            # 读取数据\n",
    "            df = cudf.read_parquet(files[k])\n",
    "            df.ts = (df.ts/1000).astype('int32')\n",
    "            df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n",
    "            df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "            # 对数量短的session进行过滤\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n', axis=1)\n",
    "            # 创建商品对\n",
    "            df = df.merge(df, on='session')\n",
    "            df = df.loc[((df.ts_x-df.ts_y).abs()<24*60*60)&(df.aid_x!=df.aid_y)]\n",
    "            # 分步统计，节省内存\n",
    "            df = df.loc[(df.aid_x >= part*size)&(df.aid_x < (part+1)*size)]\n",
    "            # 分配权重\n",
    "            df = df[['session', 'aid_x', 'aid_y', 'type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = 1\n",
    "            df = df[['aid_x', 'aid_y', 'wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x', 'aid_y']).wgt.sum()\n",
    "            # 合并分块\n",
    "            if k == a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k, ' ', end='')\n",
    "        print()\n",
    "        if a==0: tmp = tmp2\n",
    "        else:  tmp = tmp.add(tmp2, fill_value=0)  \n",
    "        gc.collect()\n",
    "    # 将矩阵转换为dict\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x', 'wgt'], ascending=[True, False])\n",
    "    # 保存前40\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n', axis=1)\n",
    "    # 分块保存在磁盘中\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    os.makedirs(path_top_40_buy2buy, exist_ok=True)\n",
    "    with open(os.path.join(path_top_40_buy2buy, 'top_40_buy2buy_v{}_{}.pkl'.format(VERSION, part)), 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7fd75",
   "metadata": {},
   "source": [
    "### “点击/收藏/购买”共现矩阵-时间加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dbcd7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T06:09:39.226413Z",
     "iopub.status.busy": "2022-11-13T06:09:39.225994Z",
     "iopub.status.idle": "2022-11-13T06:13:10.552635Z",
     "shell.execute_reply": "2022-11-13T06:13:10.551434Z",
     "shell.execute_reply.started": "2022-11-13T06:09:39.226372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "正在处理第0-22部分的数据\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  \n",
      "正在处理第22-44部分的数据\n",
      "22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  \n",
      "正在处理第44-66部分的数据\n",
      "44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  \n",
      "正在处理第66-88部分的数据\n",
      "66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  \n",
      "正在处理第88-110部分的数据\n",
      "88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  \n",
      "正在处理第110-129部分的数据\n",
      "110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  \n",
      "CPU times: user 2min 54s, sys: 35.5 s, total: 3min 29s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "type_labels = {\"clicks\":0, \"carts\":1, \"orders\":2} \n",
    "\n",
    "disk_pices = 4\n",
    "size = 1.86e6/disk_pices\n",
    "\n",
    "# 分块计算共现矩阵\n",
    "for part in range(disk_pices):\n",
    "    \n",
    "    # 分块读取数据集\n",
    "    for j in range(6):\n",
    "        a = j*chunk\n",
    "        b = min((j+1)*chunk, len(files))\n",
    "        print(\"正在处理第{}-{}部分的数据\".format(a, b))\n",
    "\n",
    "        for k in range(a, b):\n",
    "            # 读取数据\n",
    "            df = cudf.read_parquet(files[k])\n",
    "            df.ts = (df.ts/1000).astype('int32')\n",
    "            df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n",
    "            df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "            # 对数量短的session进行过滤\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n', axis=1)\n",
    "            # 创建商品对\n",
    "            df = df.merge(df, on='session')\n",
    "            df = df.loc[((df.ts_x-df.ts_y).abs()<24*60*60)&(df.aid_x!=df.aid_y)]\n",
    "            # 分步统计，节省内存\n",
    "            df = df.loc[(df.aid_x >= part*size)&(df.aid_x < (part+1)*size)]\n",
    "            # 分配权重\n",
    "            df = df[['session', 'aid_x', 'aid_y', 'ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "            df = df[['aid_x', 'aid_y', 'wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x', 'aid_y']).wgt.sum()\n",
    "            # 合并分块\n",
    "            if k == a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k, ' ', end='')\n",
    "        print()\n",
    "        if a==0: tmp = tmp2\n",
    "        else:  tmp = tmp.add(tmp2, fill_value=0)  \n",
    "        gc.collect()\n",
    "    # 将矩阵转换为dict\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x', 'wgt'], ascending=[True, False])\n",
    "    # 保存前40\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n', axis=1)\n",
    "    # 分块保存在磁盘中\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    os.makedirs(path_top_40_clicks, exist_ok=True)\n",
    "    with open(os.path.join(path_top_40_clicks, 'top_40_clicks_v{}_{}.pkl'.format(VERSION, part)), 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3487a34",
   "metadata": {},
   "source": [
    "## Setp 2 ReRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1007b0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T06:36:53.518368Z",
     "iopub.status.busy": "2022-11-13T06:36:53.517978Z",
     "iopub.status.idle": "2022-11-13T06:36:56.526026Z",
     "shell.execute_reply": "2022-11-13T06:36:56.511551Z",
     "shell.execute_reply.started": "2022-11-13T06:36:53.518335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has shape (6928123, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>2022-08-29 17:57:12.997</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>2022-08-29 17:57:42.852</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13099779</td>\n",
       "      <td>972319</td>\n",
       "      <td>2022-08-29 17:58:08.830</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13099779</td>\n",
       "      <td>972319</td>\n",
       "      <td>2022-08-29 17:58:18.486</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>2022-08-29 17:58:27.482</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session     aid                      ts    type\n",
       "0  13099779  245308 2022-08-29 17:57:12.997  clicks\n",
       "1  13099779  245308 2022-08-29 17:57:42.852   carts\n",
       "2  13099779  972319 2022-08-29 17:58:08.830  clicks\n",
       "3  13099779  972319 2022-08-29 17:58:18.486   carts\n",
       "4  13099779  245308 2022-08-29 17:58:27.482  clicks"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_test():    \n",
    "    dfs = []\n",
    "    for e, chunk_file in enumerate(glob.glob('{}/*'.format(path_parquet_test))):\n",
    "        chunk = pd.read_parquet(chunk_file)\n",
    "        dfs.append(chunk)\n",
    "    return pd.concat(dfs).reset_index(drop=True).astype({\"ts\": \"datetime64[ms]\"})\n",
    "\n",
    "df_test = load_test()\n",
    "print('Test data has shape',df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a26830d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T06:36:56.528237Z",
     "iopub.status.busy": "2022-11-13T06:36:56.527919Z",
     "iopub.status.idle": "2022-11-13T06:37:12.293669Z",
     "shell.execute_reply": "2022-11-13T06:37:12.292664Z",
     "shell.execute_reply.started": "2022-11-13T06:36:56.528207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共现矩阵的长度:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1114975, 276707, 1835928)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 共现矩阵的结果\n",
    "\n",
    "top_20_clicks = pickle.load(open(os.path.join(path_top_40_clicks,\n",
    "                                'top_40_clicks_v{}_0.pkl'.format(VERSION)), 'rb'))\n",
    "for k in range(1,disk_pices): \n",
    "    top_20_clicks.update(pickle.load(open(os.path.join(path_top_40_clicks,\n",
    "                                'top_40_clicks_v{}_{}.pkl'.format(VERSION, k)), 'rb')))\n",
    "\n",
    "top_20_buys = pickle.load(open(os.path.join(path_top_40_carts_orders,\n",
    "                                'top_40_carts_orders_v{}_0.pkl'.format(VERSION)), 'rb'))\n",
    "for k in range(1,disk_pices): \n",
    "    top_20_buys.update( pickle.load(open(os.path.join(path_top_40_carts_orders,\n",
    "                                'top_40_carts_orders_v{}_{}.pkl'.format(VERSION, k)), 'rb')))\n",
    "\n",
    "top_20_buy2buy = pickle.load(open(os.path.join(path_top_40_buy2buy,\n",
    "                                'top_40_buy2buy_v{}_{}.pkl'.format(VERSION, k)), 'rb'))\n",
    "\n",
    "# 测试集中的热门点击\n",
    "top_clicks = df_test.loc[df_test['type']=='clicks','aid'].value_counts().index.values[:20]\n",
    "top_orders = df_test.loc[df_test['type']=='orders','aid'].value_counts().index.values[:20]\n",
    "\n",
    "print('共现矩阵的长度:')\n",
    "len( top_20_clicks ), len( top_20_buy2buy ), len( top_20_buys )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8aefc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T04:48:19.398332Z",
     "start_time": "2022-11-13T04:48:19.378989Z"
    },
    "execution": {
     "iopub.execute_input": "2022-11-13T06:37:12.296491Z",
     "iopub.status.busy": "2022-11-13T06:37:12.296071Z",
     "iopub.status.idle": "2022-11-13T06:37:12.312991Z",
     "shell.execute_reply": "2022-11-13T06:37:12.311945Z",
     "shell.execute_reply.started": "2022-11-13T06:37:12.296426Z"
    }
   },
   "outputs": [],
   "source": [
    "type_weight_multipliers = {'clicks': 1, 'carts': 6, 'orders': 3}\n",
    "\n",
    "def suggest_clicks(df):\n",
    "    # 用户历史浏览商品记录及类型\n",
    "    aids = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "    # 通过权重进行重排序\n",
    "    if len(unique_aids)>=20:\n",
    "        # 时间加权\n",
    "        weights = np.logspace(0.1, 1, len(aids), base=2, endpoint=True)-1\n",
    "        aids_temp = Counter()\n",
    "        # 使用商品出现次数及其类型进行重排序\n",
    "        for aid, w, t in zip(aids, weights, types):\n",
    "            aids_temp[aid] += w*type_weight_multipliers[t]\n",
    "        sorted_aids = [k for k, v in aids_temp.most_common(20)]\n",
    "        return sorted_aids\n",
    "    # 使用“点击/收藏/购买”共现矩阵\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    # 重排序\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids]\n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    # 使用测试集合的top20的点击\n",
    "    return result + list(top_clicks)[:20-len(result)]\n",
    "\n",
    "def suggest_buys(df):\n",
    "    # 用户列浏览商品记录和类型\n",
    "    aids = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "    df = df.loc[(df['type']=='carts')|df['type']=='orders']\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "    # 通过权重进行重排序\n",
    "    if len(unique_aids)>=20:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # 使用buy2buy矩阵进行重排序\n",
    "        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "        for aid in aids3: aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k, v in aids_temp.most_common(20)]\n",
    "        return sorted_aids\n",
    "    # “点击/收藏/购买”共现矩阵\n",
    "    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n",
    "    # 使用buy2buy矩阵进行重排序\n",
    "    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "    # 重排序\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids]\n",
    "    result = unique_aids + top_aids2[:20-len(unique_aids)]\n",
    "    \n",
    "    return result + list(top_orders)[:20-len(result)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddf6ac",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2269ce83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T06:37:12.316198Z",
     "iopub.status.busy": "2022-11-13T06:37:12.315652Z",
     "iopub.status.idle": "2022-11-13T07:12:48.225090Z",
     "shell.execute_reply": "2022-11-13T07:12:48.224010Z",
     "shell.execute_reply.started": "2022-11-13T06:37:12.316162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 18s, sys: 12.1 s, total: 35min 30s\n",
      "Wall time: 35min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_df_clicks = df_test.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_clicks(x)\n",
    ")\n",
    "\n",
    "pred_df_buys = df_test.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_buys(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e58270bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T07:12:48.227562Z",
     "iopub.status.busy": "2022-11-13T07:12:48.226840Z",
     "iopub.status.idle": "2022-11-13T07:12:52.153611Z",
     "shell.execute_reply": "2022-11-13T07:12:52.152590Z",
     "shell.execute_reply.started": "2022-11-13T07:12:48.227523Z"
    }
   },
   "outputs": [],
   "source": [
    "clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a52ab3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T07:16:39.603025Z",
     "iopub.status.busy": "2022-11-13T07:16:39.602325Z",
     "iopub.status.idle": "2022-11-13T07:17:24.421246Z",
     "shell.execute_reply": "2022-11-13T07:17:24.420035Z",
     "shell.execute_reply.started": "2022-11-13T07:16:39.602988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>59625 1460571 485256 108125 986164 1551213 754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>1142000 736515 973453 582732 487136 1263108 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>918667 199008 194067 57315 141736 1069146 1375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>834354 595994 740494 889671 987399 779477 1344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_clicks  59625 1460571 485256 108125 986164 1551213 754...\n",
       "1  12899780_clicks  1142000 736515 973453 582732 487136 1263108 17...\n",
       "2  12899781_clicks  918667 199008 194067 57315 141736 1069146 1375...\n",
       "3  12899782_clicks  834354 595994 740494 889671 987399 779477 1344...\n",
       "4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n",
    "\n",
    "os.makedirs(path_submission, exist_ok=True)\n",
    "pred_df.to_csv(os.path.join(path_submission, time.strftime('submission_%Y%m%d%H%M.csv')), index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
